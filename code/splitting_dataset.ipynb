{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adf7d30-4f25-45a8-9ef4-c06f5ac3dc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result (student_info) distribution in each set:\n",
      "\n",
      "Pass:\n",
      "Train: 1814 (14.68%)\n",
      "Val:   604 (4.89%)\n",
      "Test:  9943 (80.44%)\n",
      "\n",
      "Withdrawn:\n",
      "Train: 1814 (17.86%)\n",
      "Val:   604 (5.95%)\n",
      "Test:  7738 (76.19%)\n",
      "\n",
      "Fail:\n",
      "Train: 1814 (25.72%)\n",
      "Val:   604 (8.56%)\n",
      "Test:  4634 (65.71%)\n",
      "\n",
      "Distinction:\n",
      "Train: 1814 (59.99%)\n",
      "Val:   604 (19.97%)\n",
      "Test:  606 (20.04%)\n",
      "\n",
      "Distribution result by tables:\n",
      "\n",
      "Student Info:\n",
      "Train: 7256\n",
      "Val:   2416\n",
      "Test:  22921\n",
      "\n",
      "Student VLE:\n",
      "Train: 2089547\n",
      "Val:   719804\n",
      "Test:  5649969\n",
      "\n",
      "Student Registration:\n",
      "Train: 7256\n",
      "Val:   2416\n",
      "Test:  22921\n",
      "\n",
      "Student Assessment:\n",
      "Train: 41177\n",
      "Val:   13755\n",
      "Test:  118980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# This ensures it saves to Desktop/newData regardless of OS\n",
    "OUTPUT_DIR = Path.home() / \"Desktop\" / \"newData\"\n",
    "\n",
    "# Loading tables\n",
    "student_info = pd.read_csv(\"studentInfo.csv\")\n",
    "student_vle = pd.read_csv(\"studentVle.csv\")\n",
    "student_reg = pd.read_csv(\"studentRegistration.csv\")\n",
    "assessments = pd.read_csv(\"assessments.csv\")\n",
    "student_assessment = pd.read_csv(\"studentAssessment.csv\")\n",
    "\n",
    "# Creating unique key for each student\n",
    "# pandas applies this operation to every row\n",
    "student_info['student_key'] = (\n",
    "    student_info['code_module'] + '_' +\n",
    "    student_info['code_presentation'] + '_' +\n",
    "    student_info['id_student'].astype(str)\n",
    ")\n",
    "\n",
    "# Stratifying split by final_result\n",
    "np.random.seed(42) # For reproducibility\n",
    "train_keys, val_keys, test_keys = set(), set(), set()\n",
    "\n",
    "for result in student_info['final_result'].unique():\n",
    "    subset = student_info[student_info['final_result'] == result]\n",
    "    keys = subset['student_key'].unique()\n",
    "    np.random.shuffle(keys)\n",
    "\n",
    "    # Total number of students with this final result\n",
    "    total_students = len(keys)\n",
    "\n",
    "    num_train = int(0.6 * total_students)\n",
    "    num_val = int(0.2 * total_students)\n",
    "    # The rest will go to the test set\n",
    "\n",
    "    # Adding multiple elements with .update()\n",
    "    train_keys.update(keys[0:n_train]) # 60%\n",
    "    val_keys.update(keys[n_train:n_train + n_val]) # 20%\n",
    "    test_keys.update(keys[n_train + n_val:len(keys)]) # the remaining 20%\n",
    "\n",
    "# Key columns\n",
    "key_cols = ['code_module', 'code_presentation', 'id_student']\n",
    "\n",
    "# Function to filter a DataFrame based on selected student keys\n",
    "def filter_by_keys(df, key_columns, selected_keys):\n",
    "    # 1. Creating a new column called 'student_key' in the given DataFrame\n",
    "    df['student_key'] = (\n",
    "        df[key_columns[0]] + '_' +                # e.g., 'F2'\n",
    "        df[key_columns[1]] + '_' +                # e.g., '2014J'\n",
    "        df[key_columns[2]].astype(str)            # e.g., '654321'\n",
    "    )\n",
    "    # student_key becomes something like \"F2_2014J_654321\"\n",
    "\n",
    "    # 2. Keeping only the rows where this student_key is in the selected_keys set\n",
    "    df_filtered = df[df['student_key'].isin(selected_keys)]\n",
    "\n",
    "    # 3. Dropping the student_key column to return the DataFrame to its original shape\n",
    "    return df_filtered.drop(columns=['student_key'])\n",
    "\n",
    "# .copy() creates a separate copy\n",
    "train_info = filter_by_keys(student_info.copy(), key_cols, train_keys)\n",
    "val_info = filter_by_keys(student_info.copy(), key_cols, val_keys)\n",
    "test_info = filter_by_keys(student_info.copy(), key_cols, test_keys)\n",
    "\n",
    "train_vle = filter_by_keys(student_vle.copy(), key_cols, train_keys)\n",
    "val_vle = filter_by_keys(student_vle.copy(), key_cols, val_keys)\n",
    "test_vle = filter_by_keys(student_vle.copy(), key_cols, test_keys)\n",
    "\n",
    "train_reg = filter_by_keys(student_reg.copy(), key_cols, train_keys)\n",
    "val_reg = filter_by_keys(student_reg.copy(), key_cols, val_keys)\n",
    "test_reg = filter_by_keys(student_reg.copy(), key_cols, test_keys)\n",
    "\n",
    "# Adding module and presentation to student_assessment\n",
    "student_assessment = pd.merge(\n",
    "    student_assessment,\n",
    "    assessments[['id_assessment', 'code_module', 'code_presentation']],\n",
    "    on='id_assessment',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "train_assessment = filter_by_keys(student_assessment.copy(), key_cols, train_keys)\n",
    "val_assessment = filter_by_keys(student_assessment.copy(), key_cols, val_keys)\n",
    "test_assessment = filter_by_keys(student_assessment.copy(), key_cols, test_keys)\n",
    "\n",
    "\n",
    "def save_splitted_data(train_data, val_data, test_data, table):\n",
    "    # Creating a directory at the given path.\n",
    "    # exist_ok=True means that if the folder already exists, donâ€™t raise an error, just continue.\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"val\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"test\"), exist_ok=True)\n",
    "\n",
    "    train_data.to_csv(os.path.join(OUTPUT_DIR, \"train\", f\"{table}.csv\"), index=False)\n",
    "    val_data.to_csv(os.path.join(OUTPUT_DIR, \"val\", f\"{table}.csv\"), index=False)\n",
    "    test_data.to_csv(os.path.join(OUTPUT_DIR, \"test\", f\"{table}.csv\"), index=False)\n",
    "\n",
    "save_splitted_data(train_info, val_info, test_info, 'student_info')\n",
    "save_splitted_data(train_vle, val_vle, test_vle, 'student_vle')\n",
    "save_splitted_data(train_reg, val_reg, test_reg, 'student_registration')\n",
    "save_splitted_data(train_assessment, val_assessment, test_assessment, 'student_assessment')\n",
    "\n",
    "print(\"Final result (student_info) distribution in each set:\\n\")\n",
    "\n",
    "for label in student_info['final_result'].unique():\n",
    "    train_count = (train_info['final_result'] == label).sum()\n",
    "    val_count = (val_info['final_result'] == label).sum()\n",
    "    test_count = (test_info['final_result'] == label).sum()\n",
    "    total = train_count + val_count + test_count\n",
    "\n",
    "    print(f\"{label}:\")\n",
    "    print(f\"Train: {train_count} ({train_count/total:.2%})\")\n",
    "    print(f\"Val:   {val_count} ({val_count/total:.2%})\")\n",
    "    print(f\"Test:  {test_count} ({test_count/total:.2%})\\n\")\n",
    "\n",
    "print(\"Distribution result by tables:\\n\")\n",
    "\n",
    "def print_counts(name, train_df, val_df, test_df):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Train: {len(train_df)}\")\n",
    "    print(f\"Val:   {len(val_df)}\")\n",
    "    print(f\"Test:  {len(test_df)}\\n\")\n",
    "\n",
    "print_counts(\"Student Info\", train_info, val_info, test_info)\n",
    "print_counts(\"Student VLE\", train_vle, val_vle, test_vle)\n",
    "print_counts(\"Student Registration\", train_reg, val_reg, test_reg)\n",
    "print_counts(\"Student Assessment\", train_assessment, val_assessment, test_assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2164df6-377d-44da-b856-52a01e5817c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85077e79-9fed-49fc-8b8f-f3143d5b17ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
