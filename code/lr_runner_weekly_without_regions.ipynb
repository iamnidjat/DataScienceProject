{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838816e0-81ca-47a9-93df-2cfaba595f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for the WEEK 1\n",
      "Found 18167 rows with NaN values\n",
      "Found 6091 rows with NaN values\n",
      "Found 6100 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6733159429185208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      3076\n",
      "           1       0.70      0.66      0.68      3441\n",
      "\n",
      "    accuracy                           0.67      6517\n",
      "   macro avg       0.67      0.67      0.67      6517\n",
      "weighted avg       0.68      0.67      0.67      6517\n",
      "\n",
      "Test Accuracy: 0.6738730450781969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67      3079\n",
      "           1       0.71      0.65      0.68      3443\n",
      "\n",
      "    accuracy                           0.67      6522\n",
      "   macro avg       0.67      0.68      0.67      6522\n",
      "weighted avg       0.68      0.67      0.67      6522\n",
      "\n",
      "Validation ROC AUC: 0.7428\n",
      "Test ROC AUC: 0.7408\n",
      "Validation PR AUC: 0.7817\n",
      "Test PR AUC: 0.7824\n",
      "Performance for the WEEK 2\n",
      "Found 12711 rows with NaN values\n",
      "Found 4238 rows with NaN values\n",
      "Found 4319 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6806812950744208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3076\n",
      "           1       0.71      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.68      0.68      6517\n",
      "weighted avg       0.68      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.6798528058877645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3079\n",
      "           1       0.71      0.66      0.69      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.68      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7554\n",
      "Test ROC AUC: 0.7545\n",
      "Validation PR AUC: 0.7996\n",
      "Test PR AUC: 0.8020\n",
      "Performance for the WEEK 3\n",
      "Found 8291 rows with NaN values\n",
      "Found 2778 rows with NaN values\n",
      "Found 2780 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.684517415988952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68      3076\n",
      "           1       0.71      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.69      0.68      6517\n",
      "weighted avg       0.69      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.6778595522845753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3079\n",
      "           1       0.71      0.66      0.68      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.68      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7634\n",
      "Test ROC AUC: 0.7574\n",
      "Validation PR AUC: 0.8073\n",
      "Test PR AUC: 0.8065\n",
      "Performance for the WEEK 4\n",
      "Found 6800 rows with NaN values\n",
      "Found 2303 rows with NaN values\n",
      "Found 2295 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6883535369034832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      3076\n",
      "           1       0.72      0.67      0.70      3441\n",
      "\n",
      "    accuracy                           0.69      6517\n",
      "   macro avg       0.69      0.69      0.69      6517\n",
      "weighted avg       0.69      0.69      0.69      6517\n",
      "\n",
      "Test Accuracy: 0.6896657467034651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      3079\n",
      "           1       0.72      0.67      0.70      3443\n",
      "\n",
      "    accuracy                           0.69      6522\n",
      "   macro avg       0.69      0.69      0.69      6522\n",
      "weighted avg       0.69      0.69      0.69      6522\n",
      "\n",
      "Validation ROC AUC: 0.7752\n",
      "Test ROC AUC: 0.7706\n",
      "Validation PR AUC: 0.8160\n",
      "Test PR AUC: 0.8168\n",
      "Performance for the WEEK 5\n",
      "Found 6578 rows with NaN values\n",
      "Found 2231 rows with NaN values\n",
      "Found 2222 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6964861132422894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      3076\n",
      "           1       0.72      0.69      0.71      3441\n",
      "\n",
      "    accuracy                           0.70      6517\n",
      "   macro avg       0.70      0.70      0.70      6517\n",
      "weighted avg       0.70      0.70      0.70      6517\n",
      "\n",
      "Test Accuracy: 0.6951855259122969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      3079\n",
      "           1       0.73      0.68      0.70      3443\n",
      "\n",
      "    accuracy                           0.70      6522\n",
      "   macro avg       0.70      0.70      0.70      6522\n",
      "weighted avg       0.70      0.70      0.70      6522\n",
      "\n",
      "Validation ROC AUC: 0.7853\n",
      "Test ROC AUC: 0.7782\n",
      "Validation PR AUC: 0.8237\n",
      "Test PR AUC: 0.8224\n",
      "Performance for the WEEK 6\n",
      "Found 6390 rows with NaN values\n",
      "Found 2166 rows with NaN values\n",
      "Found 2172 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7161270523246893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      3076\n",
      "           1       0.74      0.71      0.72      3441\n",
      "\n",
      "    accuracy                           0.72      6517\n",
      "   macro avg       0.72      0.72      0.72      6517\n",
      "weighted avg       0.72      0.72      0.72      6517\n",
      "\n",
      "Test Accuracy: 0.7118981907390372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71      3079\n",
      "           1       0.74      0.69      0.72      3443\n",
      "\n",
      "    accuracy                           0.71      6522\n",
      "   macro avg       0.71      0.71      0.71      6522\n",
      "weighted avg       0.71      0.71      0.71      6522\n",
      "\n",
      "Validation ROC AUC: 0.7996\n",
      "Test ROC AUC: 0.7940\n",
      "Validation PR AUC: 0.8370\n",
      "Test PR AUC: 0.8337\n",
      "Performance for the WEEK 7\n",
      "Found 5617 rows with NaN values\n",
      "Found 1914 rows with NaN values\n",
      "Found 1909 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7294767531072579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3076\n",
      "           1       0.76      0.71      0.73      3441\n",
      "\n",
      "    accuracy                           0.73      6517\n",
      "   macro avg       0.73      0.73      0.73      6517\n",
      "weighted avg       0.73      0.73      0.73      6517\n",
      "\n",
      "Test Accuracy: 0.7255443115608708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3079\n",
      "           1       0.76      0.71      0.73      3443\n",
      "\n",
      "    accuracy                           0.73      6522\n",
      "   macro avg       0.73      0.73      0.73      6522\n",
      "weighted avg       0.73      0.73      0.73      6522\n",
      "\n",
      "Validation ROC AUC: 0.8191\n",
      "Test ROC AUC: 0.8117\n",
      "Validation PR AUC: 0.8580\n",
      "Test PR AUC: 0.8535\n",
      "Performance for the WEEK 8\n",
      "Found 5547 rows with NaN values\n",
      "Found 1891 rows with NaN values\n",
      "Found 1887 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7368421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      3076\n",
      "           1       0.77      0.72      0.74      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.728457528365532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3079\n",
      "           1       0.76      0.71      0.73      3443\n",
      "\n",
      "    accuracy                           0.73      6522\n",
      "   macro avg       0.73      0.73      0.73      6522\n",
      "weighted avg       0.73      0.73      0.73      6522\n",
      "\n",
      "Validation ROC AUC: 0.8235\n",
      "Test ROC AUC: 0.8156\n",
      "Validation PR AUC: 0.8621\n",
      "Test PR AUC: 0.8573\n",
      "Performance for the WEEK 9\n",
      "Found 5500 rows with NaN values\n",
      "Found 1878 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7426730090532454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74      3076\n",
      "           1       0.77      0.73      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.735510579576817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      3079\n",
      "           1       0.77      0.72      0.74      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8310\n",
      "Test ROC AUC: 0.8252\n",
      "Validation PR AUC: 0.8677\n",
      "Test PR AUC: 0.8635\n",
      "Performance for the WEEK 10\n",
      "Found 5487 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7445143470922203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      3076\n",
      "           1       0.77      0.73      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.75      0.74      6517\n",
      "weighted avg       0.75      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7375038331800061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      3079\n",
      "           1       0.77      0.72      0.74      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8325\n",
      "Test ROC AUC: 0.8276\n",
      "Validation PR AUC: 0.8691\n",
      "Test PR AUC: 0.8650\n",
      "Performance for the WEEK 11\n",
      "Found 5483 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7440540125824766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      3076\n",
      "           1       0.77      0.73      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.75      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7421036491873658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      3079\n",
      "           1       0.77      0.73      0.75      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8345\n",
      "Test ROC AUC: 0.8289\n",
      "Validation PR AUC: 0.8707\n",
      "Test PR AUC: 0.8668\n",
      "Performance for the WEEK 12\n",
      "Found 5474 rows with NaN values\n",
      "Found 1873 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7514193647383766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      3076\n",
      "           1       0.77      0.75      0.76      3441\n",
      "\n",
      "    accuracy                           0.75      6517\n",
      "   macro avg       0.75      0.75      0.75      6517\n",
      "weighted avg       0.75      0.75      0.75      6517\n",
      "\n",
      "Test Accuracy: 0.7437902483900644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73      3079\n",
      "           1       0.77      0.74      0.75      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8428\n",
      "Test ROC AUC: 0.8356\n",
      "Validation PR AUC: 0.8766\n",
      "Test PR AUC: 0.8717\n",
      "Performance for the WEEK 13\n",
      "Found 5464 rows with NaN values\n",
      "Found 1870 rows with NaN values\n",
      "Found 1863 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7595519410771827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      3076\n",
      "           1       0.78      0.76      0.77      3441\n",
      "\n",
      "    accuracy                           0.76      6517\n",
      "   macro avg       0.76      0.76      0.76      6517\n",
      "weighted avg       0.76      0.76      0.76      6517\n",
      "\n",
      "Test Accuracy: 0.7532965348052745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74      3079\n",
      "           1       0.78      0.75      0.76      3443\n",
      "\n",
      "    accuracy                           0.75      6522\n",
      "   macro avg       0.75      0.75      0.75      6522\n",
      "weighted avg       0.75      0.75      0.75      6522\n",
      "\n",
      "Validation ROC AUC: 0.8534\n",
      "Test ROC AUC: 0.8471\n",
      "Validation PR AUC: 0.8839\n",
      "Test PR AUC: 0.8793\n",
      "Performance for the WEEK 14\n",
      "Found 5460 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Found 1861 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7659966242135953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      3076\n",
      "           1       0.79      0.76      0.77      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7566697332106715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75      3079\n",
      "           1       0.78      0.75      0.77      3443\n",
      "\n",
      "    accuracy                           0.76      6522\n",
      "   macro avg       0.76      0.76      0.76      6522\n",
      "weighted avg       0.76      0.76      0.76      6522\n",
      "\n",
      "Validation ROC AUC: 0.8590\n",
      "Test ROC AUC: 0.8516\n",
      "Validation PR AUC: 0.8884\n",
      "Test PR AUC: 0.8829\n",
      "Performance for the WEEK 15\n",
      "Found 5449 rows with NaN values\n",
      "Found 1867 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7784256559766763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      3076\n",
      "           1       0.80      0.77      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.78      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.77016252683226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      3079\n",
      "           1       0.80      0.76      0.78      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.77      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8690\n",
      "Test ROC AUC: 0.8626\n",
      "Validation PR AUC: 0.8977\n",
      "Test PR AUC: 0.8924\n",
      "Performance for the WEEK 16\n",
      "Found 5446 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Found 1856 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7821083320546264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      3076\n",
      "           1       0.81      0.77      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.78      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7779822140447715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      3079\n",
      "           1       0.80      0.77      0.79      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.78      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8730\n",
      "Test ROC AUC: 0.8665\n",
      "Validation PR AUC: 0.9012\n",
      "Test PR AUC: 0.8964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "def prepare_data(set_dir, week=None):\n",
    "    data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "    assessments = pd.read_csv(f\"{data_dir}/assessments.csv\")\n",
    "    student_info = pd.read_csv(f\"{set_dir}/student_info.csv\")\n",
    "    student_assessment = pd.read_csv(f\"{set_dir}/student_assessment.csv\")\n",
    "    student_reg = pd.read_csv(f\"{set_dir}/student_reg.csv\")\n",
    "    student_vle = pd.read_csv(f\"{set_dir}/student_vle.csv\")\n",
    "\n",
    "    if week is not None:\n",
    "        student_vle = student_vle[(student_vle['date'] // 7) <= week]\n",
    "        student_assessment = student_assessment[(student_assessment['date_submitted'] // 7) <= week]\n",
    "\n",
    "        student_reg['week_registered'] = student_reg['date_registration'] // 7\n",
    "        student_reg['days_since_registration'] = (week * 7) - student_reg['date_registration']\n",
    "        student_reg['days_since_registration'] = student_reg['days_since_registration'].clip(lower=0) # if any value in the days_since_registration column is less than 0, it is set to 0\n",
    "\n",
    "        student_assessment = pd.merge(\n",
    "            student_assessment, \n",
    "            assessments[['id_assessment', 'weight', 'assessment_type']], \n",
    "            on='id_assessment', \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        student_assessment = student_assessment[student_assessment['weight'] > 0] \n",
    "        student_assessment = student_assessment[student_assessment['assessment_type'] != 'Exam']\n",
    "    \n",
    "        # Aggregate assessments per student\n",
    "        student_agg = student_assessment.groupby(\n",
    "            ['code_module', 'code_presentation', 'id_student']\n",
    "        ).agg(\n",
    "            mean_score=('score', 'mean'),\n",
    "            max_score=('score', 'max'),\n",
    "            min_score=('score', 'min'),\n",
    "            n_assessments=('score', 'count'),\n",
    "            weighted_score=('score', lambda x: (x * student_assessment.loc[x.index, 'weight']).sum() / 100)\n",
    "        ).reset_index()\n",
    "    \n",
    "        vle_agg = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "        total_clicks=('sum_click', 'sum'),\n",
    "        n_activities=('id_site', 'nunique'),\n",
    "        days_active=('date', 'nunique')\n",
    "        ).reset_index()\n",
    "\n",
    "        vle_agg['clicks_per_day'] = vle_agg['total_clicks'] / vle_agg['days_active']\n",
    "        \n",
    "        merge_keys = ['code_module', 'code_presentation', 'id_student']\n",
    "        df = student_info.merge(student_agg, on=merge_keys, how='left')\n",
    "        df = df.merge(vle_agg, on=merge_keys, how='left')\n",
    "        df = pd.merge(df, student_reg, on=merge_keys, how='left')\n",
    "    \n",
    "        nan_rows = df[df.isna().any(axis=1)]\n",
    "        print(f\"Found {len(nan_rows)} rows with NaN values\")\n",
    "        # print(nan_rows.head())\n",
    "    \n",
    "        assessment_cols = ['mean_score', 'max_score', 'min_score', 'weighted_score']\n",
    "        df[assessment_cols] = df[assessment_cols].fillna(-1)  # -1 indicates no assessments\n",
    "        df['n_assessments'] = df['n_assessments'].fillna(0)   # 0 assessments completed\n",
    "        \n",
    "        df['total_clicks'] = df['total_clicks'].fillna(0)\n",
    "        df['n_activities'] = df['n_activities'].fillna(0)\n",
    "        df['clicks_per_day'] = df['clicks_per_day'].fillna(0)\n",
    "        df['days_active'] = df['days_active'].fillna(0)\n",
    "    \n",
    "        df = df.drop(columns=['date_unregistration', 'mean_score', 'max_score', 'min_score'], errors='ignore')\n",
    "    \n",
    "        df = df.drop(columns=['n_assessments']) # because of multicollinearity\n",
    "        # Dropping equity related  features\n",
    "        df = df.drop(columns=['disability_Y', 'age_band', 'imd_band', 'highest_education', 'gender_M'])\n",
    "        # Dropping regions\n",
    "        df = df.drop(columns=[reg for reg in df.columns if reg.startswith('region_')])\n",
    "        \n",
    "        y = df['final_result'].apply(lambda x: 1 if x in ['Fail', 'Withdrawn'] else 0)  # binary target\n",
    "    \n",
    "        X = df.drop(columns=['code_module', 'code_presentation', 'id_student', 'final_result'])\n",
    "        \n",
    "        return X, y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Gets predicted probabilities for the positive class (1)\n",
    "    y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # Getting the best threshold from our function\n",
    "    # threshold = plot_precision_recall_threshold_curve(y_val, y_val_probs, desired_recall=0.9)\n",
    "\n",
    "    # if threshold is not None:\n",
    "    #    # Converting the predicted probabilities on the validation set into binary predictions using the chosen threshold.\n",
    "    #    y_val_pred_thresh = (y_val_probs >= threshold).astype(int)\n",
    "    #    print(f\"\\n=== Evaluation at threshold {threshold:.3f} ===\")\n",
    "    #    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred_thresh))\n",
    "    #    print(classification_report(y_val, y_val_pred_thresh))\n",
    "    \n",
    "    #    y_test_pred_thresh = (y_test_probs >= threshold).astype(int)\n",
    "    #    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred_thresh))\n",
    "    #    print(classification_report(y_test, y_test_pred_thresh))\n",
    "        \n",
    "    # Calculates AUC\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_probs)\n",
    "    test_pr_auc = average_precision_score(y_test, y_test_probs)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_probs)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "    \n",
    "    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\"Validation PR AUC: {val_pr_auc:.4f}\")\n",
    "    print(f\"Test PR AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "\n",
    "for week in range(1, 17):   \n",
    "    print(f\"Performance for the WEEK {week}\")\n",
    "    X_train, y_train = prepare_data(data_dir / \"train\", week)\n",
    "    X_val, y_val = prepare_data(data_dir / \"val\", week)\n",
    "    X_test, y_test = prepare_data(data_dir / \"test\", week)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fitting only on training data, then transforming all sets\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val) \n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    # Training\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',                    # Ridge regularization\n",
    "        C=1.0,                           # Inverse of alpha (C = 1 / alpha); alpha=1e-4 -> C=1e4\n",
    "        class_weight='balanced',         # Handles class imbalance\n",
    "        solver='lbfgs',                  # Default solver, good for small to medium datasets\n",
    "        max_iter=100,                    # Allows enough iterations to converge\n",
    "        random_state=42                  # For reproducibility\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(f'Converged in {model.n_iter_} iterations')\n",
    "\n",
    "    evaluate_model(model, X_val_scaled, y_val, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2bc26-30ec-4511-b6cd-208af172436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
