{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2e5e04-1597-46fc-8348-227eac81a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE: CONSTANT\n",
      "Found 5428 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "Found 1848 rows with NaN values\n",
      "Converged in [12] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8569894123062759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      3076\n",
      "           1       0.87      0.86      0.86      3441\n",
      "\n",
      "    accuracy                           0.86      6517\n",
      "   macro avg       0.86      0.86      0.86      6517\n",
      "weighted avg       0.86      0.86      0.86      6517\n",
      "\n",
      "Test Accuracy: 0.8526525605642441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      3079\n",
      "           1       0.86      0.86      0.86      3443\n",
      "\n",
      "    accuracy                           0.85      6522\n",
      "   macro avg       0.85      0.85      0.85      6522\n",
      "weighted avg       0.85      0.85      0.85      6522\n",
      "\n",
      "Validation ROC AUC: 0.9320\n",
      "Test ROC AUC: 0.9260\n",
      "Validation PR AUC: 0.9422\n",
      "Test PR AUC: 0.9388\n",
      "MODE: MEDIAN\n",
      "Found 5428 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "Found 1848 rows with NaN values\n",
      "Converged in [12] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8565290777965322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      3076\n",
      "           1       0.87      0.86      0.86      3441\n",
      "\n",
      "    accuracy                           0.86      6517\n",
      "   macro avg       0.86      0.86      0.86      6517\n",
      "weighted avg       0.86      0.86      0.86      6517\n",
      "\n",
      "Test Accuracy: 0.8526525605642441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      3079\n",
      "           1       0.86      0.86      0.86      3443\n",
      "\n",
      "    accuracy                           0.85      6522\n",
      "   macro avg       0.85      0.85      0.85      6522\n",
      "weighted avg       0.85      0.85      0.85      6522\n",
      "\n",
      "Validation ROC AUC: 0.9317\n",
      "Test ROC AUC: 0.9257\n",
      "Validation PR AUC: 0.9419\n",
      "Test PR AUC: 0.9386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "def prepare_data(set_dir):\n",
    "    data_dir = Path.home() / \"OneDrive\" / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "    assessments = pd.read_csv(f\"{data_dir}/assessments.csv\")\n",
    "    student_info = pd.read_csv(f\"{set_dir}/student_info.csv\")\n",
    "    student_assessment = pd.read_csv(f\"{set_dir}/student_assessment.csv\")\n",
    "    student_reg = pd.read_csv(f\"{set_dir}/student_reg.csv\")\n",
    "    student_vle = pd.read_csv(f\"{set_dir}/student_vle.csv\")\n",
    "    \n",
    "    student_assessment = pd.merge(\n",
    "        student_assessment, \n",
    "        assessments[['id_assessment', 'weight', 'assessment_type']], \n",
    "        on='id_assessment', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    student_assessment = student_assessment[student_assessment['weight'] > 0] \n",
    "  # student_assessment = student_assessment[student_assessment['assessment_type'] != 'Exam']\n",
    "\n",
    "    # Aggregate assessments per student\n",
    "    student_agg = student_assessment.groupby(\n",
    "        ['code_module', 'code_presentation', 'id_student']\n",
    "    ).agg(\n",
    "        mean_score=('score', 'mean'),\n",
    "        max_score=('score', 'max'),\n",
    "        min_score=('score', 'min'),\n",
    "        n_assessments=('score', 'count'),\n",
    "        weighted_score=('score', lambda x: (x * student_assessment.loc[x.index, 'weight']).sum() / 100)\n",
    "    ).reset_index()\n",
    "\n",
    "    vle_agg = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "    total_clicks=('sum_click', 'sum'),\n",
    "    n_activities=('id_site', 'nunique')\n",
    "    ).reset_index()\n",
    "    \n",
    "    merge_keys = ['code_module', 'code_presentation', 'id_student']\n",
    "    df = student_info.merge(student_agg, on=merge_keys, how='left')\n",
    "    df = df.merge(vle_agg, on=merge_keys, how='left')\n",
    "    df = pd.merge(df, student_reg, on=merge_keys, how='left')\n",
    "\n",
    "    nan_rows = df[df.isna().any(axis=1)]\n",
    "    print(f\"Found {len(nan_rows)} rows with NaN values\")\n",
    "    # print(nan_rows.head())\n",
    "\n",
    "    assessment_cols = ['mean_score', 'max_score', 'min_score', 'weighted_score']\n",
    "    df[assessment_cols] = df[assessment_cols].fillna(-1)  # -1 indicates no assessments\n",
    "    df['n_assessments'] = df['n_assessments'].fillna(0)   # 0 assessments completed\n",
    "    \n",
    "    df['total_clicks'] = df['total_clicks'].fillna(0)\n",
    "    df['n_activities'] = df['n_activities'].fillna(0)\n",
    "\n",
    "    df = df.drop(columns=['date_unregistration', 'mean_score', 'max_score', 'min_score'], errors='ignore')\n",
    "\n",
    "    df = df.drop(columns=['n_assessments']) # because of multicollinearity\n",
    "    # Dropping equity related  features\n",
    "  # df = df.drop(columns=['disability_Y', 'age_band', 'imd_band', 'highest_education', 'gender_M'])\n",
    "    # Dropping regions\n",
    "  # df = df.drop(columns=[reg for reg in df.columns if reg.startswith('region_')])\n",
    "    \n",
    "    y = df['final_result'].apply(lambda x: 1 if x in ['Fail', 'Withdrawn'] else 0)  # binary target\n",
    "\n",
    "    X = df.drop(columns=['code_module', 'code_presentation', 'id_student', 'final_result'])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Gets predicted probabilities for the positive class (1)\n",
    "    y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # Getting the best threshold from our function\n",
    "        \n",
    "    # Calculates AUC\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_probs)\n",
    "    test_pr_auc = average_precision_score(y_test, y_test_probs)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_probs)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "    \n",
    "    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\"Validation PR AUC: {val_pr_auc:.4f}\")\n",
    "    print(f\"Test PR AUC: {test_pr_auc:.4f}\")\n",
    "    \n",
    "paths = [\"constant\", \"median\"]\n",
    "\n",
    "for path in paths:\n",
    "    print(f\"MODE: {path.upper()}\")\n",
    "    data_dir = Path.home() / \"OneDrive\" / \"Desktop\" / \"Logistic Regression\" / path\n",
    "    \n",
    "    X_train, y_train = prepare_data(data_dir / \"train\")\n",
    "    X_val, y_val = prepare_data(data_dir / \"val\")\n",
    "    X_test, y_test = prepare_data(data_dir / \"test\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fitting only on training data, then transforming all sets\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val) \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Training\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',                    # Ridge regularization\n",
    "        C=1.0,                           # Inverse of alpha (C = 1 / alpha); alpha=1e-4 -> C=1e4\n",
    "        class_weight='balanced',         # Handles class imbalance\n",
    "        solver='lbfgs',                  # Default solver, good for small to medium datasets\n",
    "        max_iter=100,                    # Allows enough iterations to converge\n",
    "        random_state=42                  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(f'Converged in {model.n_iter_} iterations')\n",
    "    \n",
    "    evaluate_model(model, X_val_scaled, y_val, X_test_scaled, y_test)\n",
    "                \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1bd614-1400-497c-b7f7-3f31e326736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c3092-9df4-4f26-8247-fd7bb8fa7e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968abec-99f8-4548-8302-a5a3889840e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8da9c-411f-463b-81b4-46b104ac0123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f90ae-d80e-4bd8-a219-84a31392bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7b410-3f59-4928-aae9-afb1cebf3342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb030dea-cda0-4e22-aee4-368ffdc58981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4daa38-b894-43a5-835b-05551f16f503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
