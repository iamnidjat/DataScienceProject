{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838816e0-81ca-47a9-93df-2cfaba595f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for the WEEK 1\n",
      "Found 18167 rows with NaN values\n",
      "Found 6091 rows with NaN values\n",
      "Found 6100 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.676538284486727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67      3076\n",
      "           1       0.70      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.68      0.68      6517\n",
      "weighted avg       0.68      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.675866298681386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3079\n",
      "           1       0.71      0.66      0.68      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.68      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7437\n",
      "Test ROC AUC: 0.7430\n",
      "Validation PR AUC: 0.7835\n",
      "Test PR AUC: 0.7834\n",
      "Performance for the WEEK 2\n",
      "Found 12711 rows with NaN values\n",
      "Found 4238 rows with NaN values\n",
      "Found 4319 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6816019640939083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67      3076\n",
      "           1       0.71      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.68      0.68      6517\n",
      "weighted avg       0.68      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.6836859858938976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68      3079\n",
      "           1       0.72      0.67      0.69      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.69      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7566\n",
      "Test ROC AUC: 0.7570\n",
      "Validation PR AUC: 0.8010\n",
      "Test PR AUC: 0.8033\n",
      "Performance for the WEEK 3\n",
      "Found 8291 rows with NaN values\n",
      "Found 2778 rows with NaN values\n",
      "Found 2780 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.682062298603652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3076\n",
      "           1       0.71      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.68      0.68      6517\n",
      "weighted avg       0.68      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.682459368291935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      3079\n",
      "           1       0.71      0.67      0.69      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.68      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7645\n",
      "Test ROC AUC: 0.7598\n",
      "Validation PR AUC: 0.8084\n",
      "Test PR AUC: 0.8079\n",
      "Performance for the WEEK 4\n",
      "Found 6800 rows with NaN values\n",
      "Found 2303 rows with NaN values\n",
      "Found 2295 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6889673162498082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      3076\n",
      "           1       0.72      0.68      0.70      3441\n",
      "\n",
      "    accuracy                           0.69      6517\n",
      "   macro avg       0.69      0.69      0.69      6517\n",
      "weighted avg       0.69      0.69      0.69      6517\n",
      "\n",
      "Test Accuracy: 0.6913523459061638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      3079\n",
      "           1       0.72      0.68      0.70      3443\n",
      "\n",
      "    accuracy                           0.69      6522\n",
      "   macro avg       0.69      0.69      0.69      6522\n",
      "weighted avg       0.69      0.69      0.69      6522\n",
      "\n",
      "Validation ROC AUC: 0.7765\n",
      "Test ROC AUC: 0.7730\n",
      "Validation PR AUC: 0.8173\n",
      "Test PR AUC: 0.8186\n",
      "Performance for the WEEK 5\n",
      "Found 6578 rows with NaN values\n",
      "Found 2231 rows with NaN values\n",
      "Found 2222 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6970998925886144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      3076\n",
      "           1       0.72      0.69      0.71      3441\n",
      "\n",
      "    accuracy                           0.70      6517\n",
      "   macro avg       0.70      0.70      0.70      6517\n",
      "weighted avg       0.70      0.70      0.70      6517\n",
      "\n",
      "Test Accuracy: 0.697178779515486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      3079\n",
      "           1       0.73      0.68      0.70      3443\n",
      "\n",
      "    accuracy                           0.70      6522\n",
      "   macro avg       0.70      0.70      0.70      6522\n",
      "weighted avg       0.70      0.70      0.70      6522\n",
      "\n",
      "Validation ROC AUC: 0.7865\n",
      "Test ROC AUC: 0.7804\n",
      "Validation PR AUC: 0.8249\n",
      "Test PR AUC: 0.8243\n",
      "Performance for the WEEK 6\n",
      "Found 6390 rows with NaN values\n",
      "Found 2166 rows with NaN values\n",
      "Found 2172 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7148994936320393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      3076\n",
      "           1       0.74      0.70      0.72      3441\n",
      "\n",
      "    accuracy                           0.71      6517\n",
      "   macro avg       0.71      0.72      0.71      6517\n",
      "weighted avg       0.72      0.71      0.72      6517\n",
      "\n",
      "Test Accuracy: 0.713738117141981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71      3079\n",
      "           1       0.74      0.70      0.72      3443\n",
      "\n",
      "    accuracy                           0.71      6522\n",
      "   macro avg       0.71      0.71      0.71      6522\n",
      "weighted avg       0.72      0.71      0.71      6522\n",
      "\n",
      "Validation ROC AUC: 0.8005\n",
      "Test ROC AUC: 0.7963\n",
      "Validation PR AUC: 0.8381\n",
      "Test PR AUC: 0.8356\n",
      "Performance for the WEEK 7\n",
      "Found 5617 rows with NaN values\n",
      "Found 1914 rows with NaN values\n",
      "Found 1909 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7305508669633267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3076\n",
      "           1       0.76      0.71      0.74      3441\n",
      "\n",
      "    accuracy                           0.73      6517\n",
      "   macro avg       0.73      0.73      0.73      6517\n",
      "weighted avg       0.73      0.73      0.73      6517\n",
      "\n",
      "Test Accuracy: 0.7272309107635695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3079\n",
      "           1       0.76      0.71      0.73      3443\n",
      "\n",
      "    accuracy                           0.73      6522\n",
      "   macro avg       0.73      0.73      0.73      6522\n",
      "weighted avg       0.73      0.73      0.73      6522\n",
      "\n",
      "Validation ROC AUC: 0.8197\n",
      "Test ROC AUC: 0.8136\n",
      "Validation PR AUC: 0.8588\n",
      "Test PR AUC: 0.8551\n",
      "Performance for the WEEK 8\n",
      "Found 5547 rows with NaN values\n",
      "Found 1891 rows with NaN values\n",
      "Found 1887 rows with NaN values\n",
      "Converged in [15] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7362283259168328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      3076\n",
      "           1       0.77      0.72      0.74      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7299908003679852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      3079\n",
      "           1       0.76      0.72      0.74      3443\n",
      "\n",
      "    accuracy                           0.73      6522\n",
      "   macro avg       0.73      0.73      0.73      6522\n",
      "weighted avg       0.73      0.73      0.73      6522\n",
      "\n",
      "Validation ROC AUC: 0.8242\n",
      "Test ROC AUC: 0.8175\n",
      "Validation PR AUC: 0.8629\n",
      "Test PR AUC: 0.8590\n",
      "Performance for the WEEK 9\n",
      "Found 5500 rows with NaN values\n",
      "Found 1878 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7417523400337579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74      3076\n",
      "           1       0.77      0.72      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7353572523765716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      3079\n",
      "           1       0.77      0.72      0.74      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8321\n",
      "Test ROC AUC: 0.8272\n",
      "Validation PR AUC: 0.8689\n",
      "Test PR AUC: 0.8654\n",
      "Performance for the WEEK 10\n",
      "Found 5487 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Converged in [18] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7428264538898266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74      3076\n",
      "           1       0.77      0.73      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7370438515792702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      3079\n",
      "           1       0.77      0.72      0.74      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8334\n",
      "Test ROC AUC: 0.8295\n",
      "Validation PR AUC: 0.8702\n",
      "Test PR AUC: 0.8668\n",
      "Performance for the WEEK 11\n",
      "Found 5483 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7442074574190578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      3076\n",
      "           1       0.77      0.74      0.75      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.75      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7407237043851579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      3079\n",
      "           1       0.77      0.73      0.75      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8352\n",
      "Test ROC AUC: 0.8307\n",
      "Validation PR AUC: 0.8717\n",
      "Test PR AUC: 0.8685\n",
      "Performance for the WEEK 12\n",
      "Found 5474 rows with NaN values\n",
      "Found 1873 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Converged in [17] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7511124750652141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      3076\n",
      "           1       0.77      0.75      0.76      3441\n",
      "\n",
      "    accuracy                           0.75      6517\n",
      "   macro avg       0.75      0.75      0.75      6517\n",
      "weighted avg       0.75      0.75      0.75      6517\n",
      "\n",
      "Test Accuracy: 0.7462434835939896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      3079\n",
      "           1       0.77      0.74      0.76      3443\n",
      "\n",
      "    accuracy                           0.75      6522\n",
      "   macro avg       0.75      0.75      0.75      6522\n",
      "weighted avg       0.75      0.75      0.75      6522\n",
      "\n",
      "Validation ROC AUC: 0.8433\n",
      "Test ROC AUC: 0.8372\n",
      "Validation PR AUC: 0.8773\n",
      "Test PR AUC: 0.8732\n",
      "Performance for the WEEK 13\n",
      "Found 5464 rows with NaN values\n",
      "Found 1870 rows with NaN values\n",
      "Found 1863 rows with NaN values\n",
      "Converged in [16] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7581709375479515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      3076\n",
      "           1       0.78      0.76      0.77      3441\n",
      "\n",
      "    accuracy                           0.76      6517\n",
      "   macro avg       0.76      0.76      0.76      6517\n",
      "weighted avg       0.76      0.76      0.76      6517\n",
      "\n",
      "Test Accuracy: 0.7536031892057651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74      3079\n",
      "           1       0.78      0.75      0.76      3443\n",
      "\n",
      "    accuracy                           0.75      6522\n",
      "   macro avg       0.75      0.75      0.75      6522\n",
      "weighted avg       0.75      0.75      0.75      6522\n",
      "\n",
      "Validation ROC AUC: 0.8538\n",
      "Test ROC AUC: 0.8487\n",
      "Validation PR AUC: 0.8845\n",
      "Test PR AUC: 0.8808\n",
      "Performance for the WEEK 14\n",
      "Found 5460 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Found 1861 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7653828448672703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      3076\n",
      "           1       0.79      0.76      0.77      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.76      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7588163140141061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      3079\n",
      "           1       0.78      0.75      0.77      3443\n",
      "\n",
      "    accuracy                           0.76      6522\n",
      "   macro avg       0.76      0.76      0.76      6522\n",
      "weighted avg       0.76      0.76      0.76      6522\n",
      "\n",
      "Validation ROC AUC: 0.8593\n",
      "Test ROC AUC: 0.8533\n",
      "Validation PR AUC: 0.8889\n",
      "Test PR AUC: 0.8845\n",
      "Performance for the WEEK 15\n",
      "Found 5449 rows with NaN values\n",
      "Found 1867 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "Converged in [14] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7787325456498388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      3076\n",
      "           1       0.80      0.77      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.78      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7707758356332414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      3079\n",
      "           1       0.80      0.76      0.78      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.77      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8696\n",
      "Test ROC AUC: 0.8642\n",
      "Validation PR AUC: 0.8985\n",
      "Test PR AUC: 0.8940\n",
      "Performance for the WEEK 16\n",
      "Found 5446 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Found 1856 rows with NaN values\n",
      "Converged in [16] iterations\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7844100046033451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78      3076\n",
      "           1       0.81      0.78      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.79      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7761422876418277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      3079\n",
      "           1       0.80      0.77      0.78      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.78      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8736\n",
      "Test ROC AUC: 0.8680\n",
      "Validation PR AUC: 0.9021\n",
      "Test PR AUC: 0.8979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "def prepare_data(set_dir, week=None):\n",
    "    data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "    assessments = pd.read_csv(f\"{data_dir}/assessments.csv\")\n",
    "    student_info = pd.read_csv(f\"{set_dir}/student_info.csv\")\n",
    "    student_assessment = pd.read_csv(f\"{set_dir}/student_assessment.csv\")\n",
    "    student_reg = pd.read_csv(f\"{set_dir}/student_reg.csv\")\n",
    "    student_vle = pd.read_csv(f\"{set_dir}/student_vle.csv\")\n",
    "\n",
    "    if week is not None:\n",
    "        student_vle = student_vle[(student_vle['date'] // 7) <= week]\n",
    "        student_assessment = student_assessment[(student_assessment['date_submitted'] // 7) <= week]\n",
    "\n",
    "        student_reg['week_registered'] = student_reg['date_registration'] // 7\n",
    "        student_reg['days_since_registration'] = (week * 7) - student_reg['date_registration']\n",
    "        student_reg['days_since_registration'] = student_reg['days_since_registration'].clip(lower=0) # if any value in the days_since_registration column is less than 0, it is set to 0\n",
    "\n",
    "        student_assessment = pd.merge(\n",
    "            student_assessment, \n",
    "            assessments[['id_assessment', 'weight', 'assessment_type']], \n",
    "            on='id_assessment', \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        student_assessment = student_assessment[student_assessment['weight'] > 0] \n",
    "        student_assessment = student_assessment[student_assessment['assessment_type'] != 'Exam']\n",
    "    \n",
    "        # Aggregate assessments per student\n",
    "        student_agg = student_assessment.groupby(\n",
    "            ['code_module', 'code_presentation', 'id_student']\n",
    "        ).agg(\n",
    "            mean_score=('score', 'mean'),\n",
    "            max_score=('score', 'max'),\n",
    "            min_score=('score', 'min'),\n",
    "            n_assessments=('score', 'count'),\n",
    "            weighted_score=('score', lambda x: (x * student_assessment.loc[x.index, 'weight']).sum() / 100)\n",
    "        ).reset_index()\n",
    "    \n",
    "        vle_agg = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "        total_clicks=('sum_click', 'sum'),\n",
    "        n_activities=('id_site', 'nunique'),\n",
    "        days_active=('date', 'nunique')\n",
    "        ).reset_index()\n",
    "\n",
    "        vle_agg['clicks_per_day'] = vle_agg['total_clicks'] / vle_agg['days_active']\n",
    "        \n",
    "        merge_keys = ['code_module', 'code_presentation', 'id_student']\n",
    "        df = student_info.merge(student_agg, on=merge_keys, how='left')\n",
    "        df = df.merge(vle_agg, on=merge_keys, how='left')\n",
    "        df = pd.merge(df, student_reg, on=merge_keys, how='left')\n",
    "    \n",
    "        nan_rows = df[df.isna().any(axis=1)]\n",
    "        print(f\"Found {len(nan_rows)} rows with NaN values\")\n",
    "        # print(nan_rows.head())\n",
    "    \n",
    "        assessment_cols = ['mean_score', 'max_score', 'min_score', 'weighted_score']\n",
    "        df[assessment_cols] = df[assessment_cols].fillna(-1)  # -1 indicates no assessments\n",
    "        df['n_assessments'] = df['n_assessments'].fillna(0)   # 0 assessments completed\n",
    "        \n",
    "        df['total_clicks'] = df['total_clicks'].fillna(0)\n",
    "        df['n_activities'] = df['n_activities'].fillna(0)\n",
    "        df['clicks_per_day'] = df['clicks_per_day'].fillna(0)\n",
    "        df['days_active'] = df['days_active'].fillna(0)\n",
    "    \n",
    "        df = df.drop(columns=['date_unregistration', 'mean_score', 'max_score', 'min_score'], errors='ignore')\n",
    "    \n",
    "        df = df.drop(columns=['n_assessments']) # because of multicollinearity\n",
    "        # Dropping equity related  features\n",
    "        df = df.drop(columns=['disability_Y', 'age_band', 'imd_band', 'highest_education', 'gender_M'])\n",
    "        # Dropping regions\n",
    "       # df = df.drop(columns=[reg for reg in df.columns if reg.startswith('region_')])\n",
    "        \n",
    "        y = df['final_result'].apply(lambda x: 1 if x in ['Fail', 'Withdrawn'] else 0)  # binary target\n",
    "    \n",
    "        X = df.drop(columns=['code_module', 'code_presentation', 'id_student', 'final_result'])\n",
    "        \n",
    "        return X, y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Gets predicted probabilities for the positive class (1)\n",
    "    y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # Getting the best threshold from our function\n",
    "    # threshold = plot_precision_recall_threshold_curve(y_val, y_val_probs, desired_recall=0.9)\n",
    "\n",
    "    # if threshold is not None:\n",
    "    #    # Converting the predicted probabilities on the validation set into binary predictions using the chosen threshold.\n",
    "    #    y_val_pred_thresh = (y_val_probs >= threshold).astype(int)\n",
    "    #    print(f\"\\n=== Evaluation at threshold {threshold:.3f} ===\")\n",
    "    #    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred_thresh))\n",
    "    #    print(classification_report(y_val, y_val_pred_thresh))\n",
    "    \n",
    "    #    y_test_pred_thresh = (y_test_probs >= threshold).astype(int)\n",
    "    #    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred_thresh))\n",
    "    #    print(classification_report(y_test, y_test_pred_thresh))\n",
    "        \n",
    "    # Calculates AUC\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_probs)\n",
    "    test_pr_auc = average_precision_score(y_test, y_test_probs)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_probs)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "    \n",
    "    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\"Validation PR AUC: {val_pr_auc:.4f}\")\n",
    "    print(f\"Test PR AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "\n",
    "for week in range(1, 17):   \n",
    "    print(f\"Performance for the WEEK {week}\")\n",
    "    X_train, y_train = prepare_data(data_dir / \"train\", week)\n",
    "    X_val, y_val = prepare_data(data_dir / \"val\", week)\n",
    "    X_test, y_test = prepare_data(data_dir / \"test\", week)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fitting only on training data, then transforming all sets\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val) \n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    # Training\n",
    "    model = LogisticRegression(\n",
    "        penalty='l2',                    # Ridge regularization\n",
    "        C=1.0,                           # Inverse of alpha (C = 1 / alpha); alpha=1e-4 -> C=1e4\n",
    "        class_weight='balanced',         # Handles class imbalance\n",
    "        solver='lbfgs',                  # Default solver, good for small to medium datasets\n",
    "        max_iter=100,                    # Allows enough iterations to converge\n",
    "        random_state=42                  # For reproducibility\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(f'Converged in {model.n_iter_} iterations')\n",
    "\n",
    "    evaluate_model(model, X_val_scaled, y_val, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2bc26-30ec-4511-b6cd-208af172436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
