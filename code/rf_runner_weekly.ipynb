{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5dbb5b-99d7-4179-a556-e5a82d3855de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for the WEEK 1\n",
      "Found 18167 rows with NaN values\n",
      "Found 6091 rows with NaN values\n",
      "Found 6100 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6840570814792082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      3076\n",
      "           1       0.71      0.67      0.69      3441\n",
      "\n",
      "    accuracy                           0.68      6517\n",
      "   macro avg       0.68      0.68      0.68      6517\n",
      "weighted avg       0.69      0.68      0.68      6517\n",
      "\n",
      "Test Accuracy: 0.6862925482980681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      3079\n",
      "           1       0.72      0.67      0.69      3443\n",
      "\n",
      "    accuracy                           0.69      6522\n",
      "   macro avg       0.69      0.69      0.69      6522\n",
      "weighted avg       0.69      0.69      0.69      6522\n",
      "\n",
      "Validation ROC AUC: 0.7619\n",
      "Test ROC AUC: 0.7550\n",
      "Validation PR AUC: 0.7967\n",
      "Test PR AUC: 0.7916\n",
      "Performance for the WEEK 2\n",
      "Found 12711 rows with NaN values\n",
      "Found 4238 rows with NaN values\n",
      "Found 4319 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7044652447445143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.70      3076\n",
      "           1       0.74      0.69      0.71      3441\n",
      "\n",
      "    accuracy                           0.70      6517\n",
      "   macro avg       0.70      0.71      0.70      6517\n",
      "weighted avg       0.71      0.70      0.70      6517\n",
      "\n",
      "Test Accuracy: 0.7036185219257897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.70      3079\n",
      "           1       0.74      0.69      0.71      3443\n",
      "\n",
      "    accuracy                           0.70      6522\n",
      "   macro avg       0.70      0.70      0.70      6522\n",
      "weighted avg       0.71      0.70      0.70      6522\n",
      "\n",
      "Validation ROC AUC: 0.7838\n",
      "Test ROC AUC: 0.7760\n",
      "Validation PR AUC: 0.8221\n",
      "Test PR AUC: 0.8147\n",
      "Performance for the WEEK 3\n",
      "Found 8291 rows with NaN values\n",
      "Found 2778 rows with NaN values\n",
      "Found 2780 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.727021635721958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72      3076\n",
      "           1       0.76      0.70      0.73      3441\n",
      "\n",
      "    accuracy                           0.73      6517\n",
      "   macro avg       0.73      0.73      0.73      6517\n",
      "weighted avg       0.73      0.73      0.73      6517\n",
      "\n",
      "Test Accuracy: 0.7135847899417357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71      3079\n",
      "           1       0.75      0.68      0.71      3443\n",
      "\n",
      "    accuracy                           0.71      6522\n",
      "   macro avg       0.72      0.72      0.71      6522\n",
      "weighted avg       0.72      0.71      0.71      6522\n",
      "\n",
      "Validation ROC AUC: 0.8013\n",
      "Test ROC AUC: 0.7911\n",
      "Validation PR AUC: 0.8385\n",
      "Test PR AUC: 0.8304\n",
      "Performance for the WEEK 4\n",
      "Found 6800 rows with NaN values\n",
      "Found 2303 rows with NaN values\n",
      "Found 2295 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7340800982046954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      3076\n",
      "           1       0.77      0.71      0.74      3441\n",
      "\n",
      "    accuracy                           0.73      6517\n",
      "   macro avg       0.74      0.74      0.73      6517\n",
      "weighted avg       0.74      0.73      0.73      6517\n",
      "\n",
      "Test Accuracy: 0.7263109475620975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73      3079\n",
      "           1       0.77      0.69      0.73      3443\n",
      "\n",
      "    accuracy                           0.73      6522\n",
      "   macro avg       0.73      0.73      0.73      6522\n",
      "weighted avg       0.73      0.73      0.73      6522\n",
      "\n",
      "Validation ROC AUC: 0.8142\n",
      "Test ROC AUC: 0.8071\n",
      "Validation PR AUC: 0.8492\n",
      "Test PR AUC: 0.8437\n",
      "Performance for the WEEK 5\n",
      "Found 6578 rows with NaN values\n",
      "Found 2231 rows with NaN values\n",
      "Found 2222 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7386834433021329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.74      3076\n",
      "           1       0.78      0.71      0.74      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7352039251763263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      3079\n",
      "           1       0.77      0.71      0.74      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8228\n",
      "Test ROC AUC: 0.8164\n",
      "Validation PR AUC: 0.8553\n",
      "Test PR AUC: 0.8519\n",
      "Performance for the WEEK 6\n",
      "Found 6390 rows with NaN values\n",
      "Found 2166 rows with NaN values\n",
      "Found 2172 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7497314715359829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      3076\n",
      "           1       0.78      0.72      0.75      3441\n",
      "\n",
      "    accuracy                           0.75      6517\n",
      "   macro avg       0.75      0.75      0.75      6517\n",
      "weighted avg       0.75      0.75      0.75      6517\n",
      "\n",
      "Test Accuracy: 0.7566697332106715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      3079\n",
      "           1       0.79      0.73      0.76      3443\n",
      "\n",
      "    accuracy                           0.76      6522\n",
      "   macro avg       0.76      0.76      0.76      6522\n",
      "weighted avg       0.76      0.76      0.76      6522\n",
      "\n",
      "Validation ROC AUC: 0.8287\n",
      "Test ROC AUC: 0.8296\n",
      "Validation PR AUC: 0.8622\n",
      "Test PR AUC: 0.8614\n",
      "Performance for the WEEK 7\n",
      "Found 5617 rows with NaN values\n",
      "Found 1914 rows with NaN values\n",
      "Found 1909 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.765229400030689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.77      3076\n",
      "           1       0.81      0.72      0.77      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7670959828273536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      3079\n",
      "           1       0.81      0.72      0.77      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.77      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8434\n",
      "Test ROC AUC: 0.8460\n",
      "Validation PR AUC: 0.8782\n",
      "Test PR AUC: 0.8788\n",
      "Performance for the WEEK 8\n",
      "Found 5547 rows with NaN values\n",
      "Found 1891 rows with NaN values\n",
      "Found 1887 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7705999693110327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      3076\n",
      "           1       0.81      0.73      0.77      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.78      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7712358172339773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      3079\n",
      "           1       0.81      0.73      0.77      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.78      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8462\n",
      "Test ROC AUC: 0.8501\n",
      "Validation PR AUC: 0.8809\n",
      "Test PR AUC: 0.8838\n",
      "Performance for the WEEK 9\n",
      "Found 5500 rows with NaN values\n",
      "Found 1878 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7845634494399264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      3076\n",
      "           1       0.82      0.75      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.79      0.79      0.78      6517\n",
      "weighted avg       0.79      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7807421036491874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      3079\n",
      "           1       0.82      0.75      0.78      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.78      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8609\n",
      "Test ROC AUC: 0.8633\n",
      "Validation PR AUC: 0.8929\n",
      "Test PR AUC: 0.8939\n",
      "Performance for the WEEK 10\n",
      "Found 5487 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7821083320546264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      3076\n",
      "           1       0.82      0.75      0.78      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.79      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7821220484513953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      3079\n",
      "           1       0.83      0.74      0.78      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.79      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8611\n",
      "Test ROC AUC: 0.8638\n",
      "Validation PR AUC: 0.8930\n",
      "Test PR AUC: 0.8949\n",
      "Performance for the WEEK 11\n",
      "Found 5483 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7839496700936014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      3076\n",
      "           1       0.82      0.75      0.79      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.79      0.79      0.78      6517\n",
      "weighted avg       0.79      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7845752836553205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      3079\n",
      "           1       0.83      0.75      0.79      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.79      0.79      0.78      6522\n",
      "weighted avg       0.79      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8627\n",
      "Test ROC AUC: 0.8622\n",
      "Validation PR AUC: 0.8950\n",
      "Test PR AUC: 0.8943\n",
      "Performance for the WEEK 12\n",
      "Found 5474 rows with NaN values\n",
      "Found 1873 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7916219119226638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79      3076\n",
      "           1       0.83      0.76      0.79      3441\n",
      "\n",
      "    accuracy                           0.79      6517\n",
      "   macro avg       0.79      0.79      0.79      6517\n",
      "weighted avg       0.80      0.79      0.79      6517\n",
      "\n",
      "Test Accuracy: 0.7882551364612083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79      3079\n",
      "           1       0.83      0.76      0.79      3443\n",
      "\n",
      "    accuracy                           0.79      6522\n",
      "   macro avg       0.79      0.79      0.79      6522\n",
      "weighted avg       0.79      0.79      0.79      6522\n",
      "\n",
      "Validation ROC AUC: 0.8671\n",
      "Test ROC AUC: 0.8691\n",
      "Validation PR AUC: 0.8978\n",
      "Test PR AUC: 0.8994\n",
      "Performance for the WEEK 13\n",
      "Found 5464 rows with NaN values\n",
      "Found 1870 rows with NaN values\n",
      "Found 1863 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8012889366272825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80      3076\n",
      "           1       0.83      0.78      0.81      3441\n",
      "\n",
      "    accuracy                           0.80      6517\n",
      "   macro avg       0.80      0.80      0.80      6517\n",
      "weighted avg       0.80      0.80      0.80      6517\n",
      "\n",
      "Test Accuracy: 0.8017479300827967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      3079\n",
      "           1       0.83      0.78      0.81      3443\n",
      "\n",
      "    accuracy                           0.80      6522\n",
      "   macro avg       0.80      0.80      0.80      6522\n",
      "weighted avg       0.80      0.80      0.80      6522\n",
      "\n",
      "Validation ROC AUC: 0.8813\n",
      "Test ROC AUC: 0.8817\n",
      "Validation PR AUC: 0.9068\n",
      "Test PR AUC: 0.9074\n",
      "Performance for the WEEK 14\n",
      "Found 5460 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Found 1861 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8118766303513887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81      3076\n",
      "           1       0.84      0.79      0.82      3441\n",
      "\n",
      "    accuracy                           0.81      6517\n",
      "   macro avg       0.81      0.81      0.81      6517\n",
      "weighted avg       0.81      0.81      0.81      6517\n",
      "\n",
      "Test Accuracy: 0.8106409076970255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      3079\n",
      "           1       0.84      0.79      0.81      3443\n",
      "\n",
      "    accuracy                           0.81      6522\n",
      "   macro avg       0.81      0.81      0.81      6522\n",
      "weighted avg       0.81      0.81      0.81      6522\n",
      "\n",
      "Validation ROC AUC: 0.8887\n",
      "Test ROC AUC: 0.8869\n",
      "Validation PR AUC: 0.9124\n",
      "Test PR AUC: 0.9115\n",
      "Performance for the WEEK 15\n",
      "Found 5449 rows with NaN values\n",
      "Found 1867 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8146386374098512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      3076\n",
      "           1       0.85      0.79      0.82      3441\n",
      "\n",
      "    accuracy                           0.81      6517\n",
      "   macro avg       0.82      0.82      0.81      6517\n",
      "weighted avg       0.82      0.81      0.81      6517\n",
      "\n",
      "Test Accuracy: 0.8221404477154247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      3079\n",
      "           1       0.86      0.79      0.82      3443\n",
      "\n",
      "    accuracy                           0.82      6522\n",
      "   macro avg       0.82      0.82      0.82      6522\n",
      "weighted avg       0.83      0.82      0.82      6522\n",
      "\n",
      "Validation ROC AUC: 0.8961\n",
      "Test ROC AUC: 0.8963\n",
      "Validation PR AUC: 0.9207\n",
      "Test PR AUC: 0.9209\n",
      "Performance for the WEEK 16\n",
      "Found 5446 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Found 1856 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8252263311339574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      3076\n",
      "           1       0.86      0.80      0.83      3441\n",
      "\n",
      "    accuracy                           0.83      6517\n",
      "   macro avg       0.83      0.83      0.83      6517\n",
      "weighted avg       0.83      0.83      0.83      6517\n",
      "\n",
      "Test Accuracy: 0.827506899724011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      3079\n",
      "           1       0.86      0.80      0.83      3443\n",
      "\n",
      "    accuracy                           0.83      6522\n",
      "   macro avg       0.83      0.83      0.83      6522\n",
      "weighted avg       0.83      0.83      0.83      6522\n",
      "\n",
      "Validation ROC AUC: 0.9008\n",
      "Test ROC AUC: 0.9011\n",
      "Validation PR AUC: 0.9250\n",
      "Test PR AUC: 0.9252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "\n",
    "def prepare_data(set_dir, week=None):\n",
    "    data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "    assessments = pd.read_csv(f\"{data_dir}/assessments.csv\")\n",
    "    student_info = pd.read_csv(f\"{set_dir}/student_info.csv\")\n",
    "    student_assessment = pd.read_csv(f\"{set_dir}/student_assessment.csv\")\n",
    "    student_reg = pd.read_csv(f\"{set_dir}/student_reg.csv\")\n",
    "    student_vle = pd.read_csv(f\"{set_dir}/student_vle.csv\")\n",
    "\n",
    "    if week is not None:\n",
    "        student_vle = student_vle[(student_vle['date'] // 7) <= week]\n",
    "        student_assessment = student_assessment[(student_assessment['date_submitted'] // 7) <= week]\n",
    "\n",
    "        student_reg['week_registered'] = student_reg['date_registration'] // 7\n",
    "        student_reg['days_since_registration'] = (week * 7) - student_reg['date_registration']\n",
    "        student_reg['days_since_registration'] = student_reg['days_since_registration'].clip(lower=0) # if any value in the days_since_registration column is less than 0, it is set to 0\n",
    "\n",
    "        student_assessment = pd.merge(\n",
    "            student_assessment, \n",
    "            assessments[['id_assessment', 'weight', 'assessment_type']], \n",
    "            on='id_assessment', \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        student_assessment = student_assessment[student_assessment['weight'] > 0] \n",
    "        student_assessment = student_assessment[student_assessment['assessment_type'] != 'Exam']\n",
    "    \n",
    "        # Aggregate assessments per student\n",
    "        student_agg = student_assessment.groupby(\n",
    "            ['code_module', 'code_presentation', 'id_student']\n",
    "        ).agg(\n",
    "            mean_score=('score', 'mean'),\n",
    "            max_score=('score', 'max'),\n",
    "            min_score=('score', 'min'),\n",
    "            n_assessments=('score', 'count'),\n",
    "            weighted_score=('score', lambda x: (x * student_assessment.loc[x.index, 'weight']).sum() / 100)\n",
    "        ).reset_index()\n",
    "    \n",
    "        vle_agg = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "        total_clicks=('sum_click', 'sum'),\n",
    "        n_activities=('id_site', 'nunique'),\n",
    "        days_active=('date', 'nunique')\n",
    "        ).reset_index()\n",
    "\n",
    "        vle_agg['clicks_per_day'] = vle_agg['total_clicks'] / vle_agg['days_active']\n",
    "        \n",
    "        merge_keys = ['code_module', 'code_presentation', 'id_student']\n",
    "        df = student_info.merge(student_agg, on=merge_keys, how='left')\n",
    "        df = df.merge(vle_agg, on=merge_keys, how='left')\n",
    "        df = pd.merge(df, student_reg, on=merge_keys, how='left')\n",
    "    \n",
    "        nan_rows = df[df.isna().any(axis=1)]\n",
    "        print(f\"Found {len(nan_rows)} rows with NaN values\")\n",
    "        # print(nan_rows.head())\n",
    "    \n",
    "        assessment_cols = ['mean_score', 'max_score', 'min_score', 'weighted_score']\n",
    "        df[assessment_cols] = df[assessment_cols].fillna(-1)  # -1 indicates no assessments\n",
    "        df['n_assessments'] = df['n_assessments'].fillna(0)   # 0 assessments completed\n",
    "        \n",
    "        df['total_clicks'] = df['total_clicks'].fillna(0)\n",
    "        df['n_activities'] = df['n_activities'].fillna(0)\n",
    "        df['clicks_per_day'] = df['clicks_per_day'].fillna(0)\n",
    "        df['days_active'] = df['clicks_per_day'].fillna(0)\n",
    "    \n",
    "        df = df.drop(columns=['date_unregistration', 'mean_score', 'max_score', 'min_score'], errors='ignore')\n",
    "    \n",
    "        df = df.drop(columns=['n_assessments']) # because of multicollinearity\n",
    "        # Dropping equity related  features\n",
    "       # df = df.drop(columns=['disability_Y', 'age_band', 'imd_band', 'highest_education', 'gender_M'])\n",
    "        # Dropping regions\n",
    "       # df = df.drop(columns=[reg for reg in df.columns if reg.startswith('region_')])\n",
    "        \n",
    "        y = df['final_result'].apply(lambda x: 1 if x in ['Fail', 'Withdrawn'] else 0)  # binary target\n",
    "    \n",
    "        X = df.drop(columns=['code_module', 'code_presentation', 'id_student', 'final_result'])\n",
    "        \n",
    "        return X, y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Gets predicted probabilities for the positive class (1)\n",
    "    y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # Getting the best threshold from our function\n",
    "    # threshold = plot_precision_recall_threshold_curve(y_val, y_val_probs, desired_recall=0.9)\n",
    "\n",
    "    # if threshold is not None:\n",
    "    #    # Converting the predicted probabilities on the validation set into binary predictions using the chosen threshold.\n",
    "    #    y_val_pred_thresh = (y_val_probs >= threshold).astype(int)\n",
    "    #    print(f\"\\n=== Evaluation at threshold {threshold:.3f} ===\")\n",
    "    #    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred_thresh))\n",
    "    #    print(classification_report(y_val, y_val_pred_thresh))\n",
    "    \n",
    "    #    y_test_pred_thresh = (y_test_probs >= threshold).astype(int)\n",
    "    #    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred_thresh))\n",
    "    #    print(classification_report(y_test, y_test_pred_thresh))\n",
    "        \n",
    "    # Calculates AUC\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_probs)\n",
    "    test_pr_auc = average_precision_score(y_test, y_test_probs)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_probs)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "    \n",
    "    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\"Validation PR AUC: {val_pr_auc:.4f}\")\n",
    "    print(f\"Test PR AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "\n",
    "for week in range(1, 17):   \n",
    "    print(f\"Performance for the WEEK {week}\")\n",
    "    X_train, y_train = prepare_data(data_dir / \"train\", week)\n",
    "    X_val, y_val = prepare_data(data_dir / \"val\", week)\n",
    "    X_test, y_test = prepare_data(data_dir / \"test\", week)\n",
    "    \n",
    "    # Training\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,         # Number of trees\n",
    "        class_weight='balanced',  # Handles imbalance\n",
    "        max_depth=None,           # Lets trees grow fully\n",
    "        random_state=42,          # For reproducibility\n",
    "        n_jobs=-1                 # Uses all cores\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    evaluate_model(model, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c4e86-0d58-45ef-8f8b-b15449908f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
