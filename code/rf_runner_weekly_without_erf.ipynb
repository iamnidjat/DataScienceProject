{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5dbb5b-99d7-4179-a556-e5a82d3855de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for the WEEK 1\n",
      "Found 18167 rows with NaN values\n",
      "Found 6091 rows with NaN values\n",
      "Found 6100 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.6665643701089459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      3076\n",
      "           1       0.70      0.65      0.67      3441\n",
      "\n",
      "    accuracy                           0.67      6517\n",
      "   macro avg       0.67      0.67      0.67      6517\n",
      "weighted avg       0.67      0.67      0.67      6517\n",
      "\n",
      "Test Accuracy: 0.6634467954615149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66      3079\n",
      "           1       0.70      0.64      0.67      3443\n",
      "\n",
      "    accuracy                           0.66      6522\n",
      "   macro avg       0.66      0.66      0.66      6522\n",
      "weighted avg       0.67      0.66      0.66      6522\n",
      "\n",
      "Validation ROC AUC: 0.7338\n",
      "Test ROC AUC: 0.7318\n",
      "Validation PR AUC: 0.7742\n",
      "Test PR AUC: 0.7699\n",
      "Performance for the WEEK 2\n",
      "Found 12711 rows with NaN values\n",
      "Found 4238 rows with NaN values\n",
      "Found 4319 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.693110326837502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.69      3076\n",
      "           1       0.72      0.68      0.70      3441\n",
      "\n",
      "    accuracy                           0.69      6517\n",
      "   macro avg       0.69      0.69      0.69      6517\n",
      "weighted avg       0.70      0.69      0.69      6517\n",
      "\n",
      "Test Accuracy: 0.6787795154860472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68      3079\n",
      "           1       0.71      0.65      0.68      3443\n",
      "\n",
      "    accuracy                           0.68      6522\n",
      "   macro avg       0.68      0.68      0.68      6522\n",
      "weighted avg       0.68      0.68      0.68      6522\n",
      "\n",
      "Validation ROC AUC: 0.7668\n",
      "Test ROC AUC: 0.7584\n",
      "Validation PR AUC: 0.8072\n",
      "Test PR AUC: 0.7986\n",
      "Performance for the WEEK 3\n",
      "Found 8291 rows with NaN values\n",
      "Found 2778 rows with NaN values\n",
      "Found 2780 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7010894583397269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.70      3076\n",
      "           1       0.73      0.68      0.71      3441\n",
      "\n",
      "    accuracy                           0.70      6517\n",
      "   macro avg       0.70      0.70      0.70      6517\n",
      "weighted avg       0.70      0.70      0.70      6517\n",
      "\n",
      "Test Accuracy: 0.704231830726771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70      3079\n",
      "           1       0.74      0.67      0.71      3443\n",
      "\n",
      "    accuracy                           0.70      6522\n",
      "   macro avg       0.71      0.71      0.70      6522\n",
      "weighted avg       0.71      0.70      0.70      6522\n",
      "\n",
      "Validation ROC AUC: 0.7818\n",
      "Test ROC AUC: 0.7782\n",
      "Validation PR AUC: 0.8235\n",
      "Test PR AUC: 0.8217\n",
      "Performance for the WEEK 4\n",
      "Found 6800 rows with NaN values\n",
      "Found 2303 rows with NaN values\n",
      "Found 2295 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7158201626515268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71      3076\n",
      "           1       0.75      0.69      0.72      3441\n",
      "\n",
      "    accuracy                           0.72      6517\n",
      "   macro avg       0.72      0.72      0.72      6517\n",
      "weighted avg       0.72      0.72      0.72      6517\n",
      "\n",
      "Test Accuracy: 0.7122048451395278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71      3079\n",
      "           1       0.75      0.68      0.71      3443\n",
      "\n",
      "    accuracy                           0.71      6522\n",
      "   macro avg       0.71      0.71      0.71      6522\n",
      "weighted avg       0.72      0.71      0.71      6522\n",
      "\n",
      "Validation ROC AUC: 0.7952\n",
      "Test ROC AUC: 0.7913\n",
      "Validation PR AUC: 0.8335\n",
      "Test PR AUC: 0.8324\n",
      "Performance for the WEEK 5\n",
      "Found 6578 rows with NaN values\n",
      "Found 2231 rows with NaN values\n",
      "Found 2222 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7193493938928955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      3076\n",
      "           1       0.75      0.70      0.72      3441\n",
      "\n",
      "    accuracy                           0.72      6517\n",
      "   macro avg       0.72      0.72      0.72      6517\n",
      "weighted avg       0.72      0.72      0.72      6517\n",
      "\n",
      "Test Accuracy: 0.7157313707451702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71      3079\n",
      "           1       0.75      0.69      0.72      3443\n",
      "\n",
      "    accuracy                           0.72      6522\n",
      "   macro avg       0.72      0.72      0.72      6522\n",
      "weighted avg       0.72      0.72      0.72      6522\n",
      "\n",
      "Validation ROC AUC: 0.8032\n",
      "Test ROC AUC: 0.8017\n",
      "Validation PR AUC: 0.8383\n",
      "Test PR AUC: 0.8403\n",
      "Performance for the WEEK 6\n",
      "Found 6390 rows with NaN values\n",
      "Found 2166 rows with NaN values\n",
      "Found 2172 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7414454503605954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      3076\n",
      "           1       0.78      0.72      0.74      3441\n",
      "\n",
      "    accuracy                           0.74      6517\n",
      "   macro avg       0.74      0.74      0.74      6517\n",
      "weighted avg       0.74      0.74      0.74      6517\n",
      "\n",
      "Test Accuracy: 0.7419503219871205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      3079\n",
      "           1       0.78      0.72      0.75      3443\n",
      "\n",
      "    accuracy                           0.74      6522\n",
      "   macro avg       0.74      0.74      0.74      6522\n",
      "weighted avg       0.74      0.74      0.74      6522\n",
      "\n",
      "Validation ROC AUC: 0.8183\n",
      "Test ROC AUC: 0.8212\n",
      "Validation PR AUC: 0.8517\n",
      "Test PR AUC: 0.8536\n",
      "Performance for the WEEK 7\n",
      "Found 5617 rows with NaN values\n",
      "Found 1914 rows with NaN values\n",
      "Found 1909 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7564830443455578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      3076\n",
      "           1       0.80      0.72      0.76      3441\n",
      "\n",
      "    accuracy                           0.76      6517\n",
      "   macro avg       0.76      0.76      0.76      6517\n",
      "weighted avg       0.76      0.76      0.76      6517\n",
      "\n",
      "Test Accuracy: 0.754983134007973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      3079\n",
      "           1       0.80      0.72      0.76      3443\n",
      "\n",
      "    accuracy                           0.75      6522\n",
      "   macro avg       0.76      0.76      0.75      6522\n",
      "weighted avg       0.76      0.75      0.76      6522\n",
      "\n",
      "Validation ROC AUC: 0.8331\n",
      "Test ROC AUC: 0.8327\n",
      "Validation PR AUC: 0.8702\n",
      "Test PR AUC: 0.8687\n",
      "Performance for the WEEK 8\n",
      "Found 5547 rows with NaN values\n",
      "Found 1891 rows with NaN values\n",
      "Found 1887 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7577106030382078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.76      3076\n",
      "           1       0.80      0.73      0.76      3441\n",
      "\n",
      "    accuracy                           0.76      6517\n",
      "   macro avg       0.76      0.76      0.76      6517\n",
      "weighted avg       0.76      0.76      0.76      6517\n",
      "\n",
      "Test Accuracy: 0.7568230604109168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      3079\n",
      "           1       0.80      0.72      0.76      3443\n",
      "\n",
      "    accuracy                           0.76      6522\n",
      "   macro avg       0.76      0.76      0.76      6522\n",
      "weighted avg       0.76      0.76      0.76      6522\n",
      "\n",
      "Validation ROC AUC: 0.8350\n",
      "Test ROC AUC: 0.8372\n",
      "Validation PR AUC: 0.8723\n",
      "Test PR AUC: 0.8743\n",
      "Performance for the WEEK 9\n",
      "Found 5500 rows with NaN values\n",
      "Found 1878 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7669172932330827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      3076\n",
      "           1       0.80      0.75      0.77      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7675559644280895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      3079\n",
      "           1       0.80      0.74      0.77      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.77      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8495\n",
      "Test ROC AUC: 0.8543\n",
      "Validation PR AUC: 0.8829\n",
      "Test PR AUC: 0.8861\n",
      "Performance for the WEEK 10\n",
      "Found 5487 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7704465244744514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      3076\n",
      "           1       0.80      0.75      0.78      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7675559644280895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      3079\n",
      "           1       0.80      0.74      0.77      3443\n",
      "\n",
      "    accuracy                           0.77      6522\n",
      "   macro avg       0.77      0.77      0.77      6522\n",
      "weighted avg       0.77      0.77      0.77      6522\n",
      "\n",
      "Validation ROC AUC: 0.8525\n",
      "Test ROC AUC: 0.8540\n",
      "Validation PR AUC: 0.8867\n",
      "Test PR AUC: 0.8866\n",
      "Performance for the WEEK 11\n",
      "Found 5483 rows with NaN values\n",
      "Found 1874 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7699861899647077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      3076\n",
      "           1       0.80      0.75      0.78      3441\n",
      "\n",
      "    accuracy                           0.77      6517\n",
      "   macro avg       0.77      0.77      0.77      6517\n",
      "weighted avg       0.77      0.77      0.77      6517\n",
      "\n",
      "Test Accuracy: 0.7759889604415824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      3079\n",
      "           1       0.81      0.75      0.78      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.78      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8526\n",
      "Test ROC AUC: 0.8558\n",
      "Validation PR AUC: 0.8868\n",
      "Test PR AUC: 0.8880\n",
      "Performance for the WEEK 12\n",
      "Found 5474 rows with NaN values\n",
      "Found 1873 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.7775049869571888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      3076\n",
      "           1       0.81      0.76      0.78      3441\n",
      "\n",
      "    accuracy                           0.78      6517\n",
      "   macro avg       0.78      0.78      0.78      6517\n",
      "weighted avg       0.78      0.78      0.78      6517\n",
      "\n",
      "Test Accuracy: 0.7827353572523765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      3079\n",
      "           1       0.82      0.75      0.78      3443\n",
      "\n",
      "    accuracy                           0.78      6522\n",
      "   macro avg       0.78      0.78      0.78      6522\n",
      "weighted avg       0.79      0.78      0.78      6522\n",
      "\n",
      "Validation ROC AUC: 0.8590\n",
      "Test ROC AUC: 0.8618\n",
      "Validation PR AUC: 0.8905\n",
      "Test PR AUC: 0.8924\n",
      "Performance for the WEEK 13\n",
      "Found 5464 rows with NaN values\n",
      "Found 1870 rows with NaN values\n",
      "Found 1863 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.80098204695412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79      3076\n",
      "           1       0.83      0.79      0.81      3441\n",
      "\n",
      "    accuracy                           0.80      6517\n",
      "   macro avg       0.80      0.80      0.80      6517\n",
      "weighted avg       0.80      0.80      0.80      6517\n",
      "\n",
      "Test Accuracy: 0.7960748236737197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79      3079\n",
      "           1       0.83      0.78      0.80      3443\n",
      "\n",
      "    accuracy                           0.80      6522\n",
      "   macro avg       0.80      0.80      0.80      6522\n",
      "weighted avg       0.80      0.80      0.80      6522\n",
      "\n",
      "Validation ROC AUC: 0.8771\n",
      "Test ROC AUC: 0.8743\n",
      "Validation PR AUC: 0.9025\n",
      "Test PR AUC: 0.9004\n",
      "Performance for the WEEK 14\n",
      "Found 5460 rows with NaN values\n",
      "Found 1869 rows with NaN values\n",
      "Found 1861 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8091146232929262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      3076\n",
      "           1       0.83      0.80      0.82      3441\n",
      "\n",
      "    accuracy                           0.81      6517\n",
      "   macro avg       0.81      0.81      0.81      6517\n",
      "weighted avg       0.81      0.81      0.81      6517\n",
      "\n",
      "Test Accuracy: 0.801901257283042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      3079\n",
      "           1       0.83      0.79      0.81      3443\n",
      "\n",
      "    accuracy                           0.80      6522\n",
      "   macro avg       0.80      0.80      0.80      6522\n",
      "weighted avg       0.80      0.80      0.80      6522\n",
      "\n",
      "Validation ROC AUC: 0.8830\n",
      "Test ROC AUC: 0.8809\n",
      "Validation PR AUC: 0.9071\n",
      "Test PR AUC: 0.9052\n",
      "Performance for the WEEK 15\n",
      "Found 5449 rows with NaN values\n",
      "Found 1867 rows with NaN values\n",
      "Found 1857 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8106490716587387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      3076\n",
      "           1       0.85      0.79      0.81      3441\n",
      "\n",
      "    accuracy                           0.81      6517\n",
      "   macro avg       0.81      0.81      0.81      6517\n",
      "weighted avg       0.81      0.81      0.81      6517\n",
      "\n",
      "Test Accuracy: 0.8107942348972708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81      3079\n",
      "           1       0.84      0.79      0.81      3443\n",
      "\n",
      "    accuracy                           0.81      6522\n",
      "   macro avg       0.81      0.81      0.81      6522\n",
      "weighted avg       0.81      0.81      0.81      6522\n",
      "\n",
      "Validation ROC AUC: 0.8907\n",
      "Test ROC AUC: 0.8909\n",
      "Validation PR AUC: 0.9163\n",
      "Test PR AUC: 0.9155\n",
      "Performance for the WEEK 16\n",
      "Found 5446 rows with NaN values\n",
      "Found 1865 rows with NaN values\n",
      "Found 1856 rows with NaN values\n",
      "\n",
      "=== Model Performance ===\n",
      "Validation Accuracy: 0.8193954273438698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      3076\n",
      "           1       0.86      0.79      0.82      3441\n",
      "\n",
      "    accuracy                           0.82      6517\n",
      "   macro avg       0.82      0.82      0.82      6517\n",
      "weighted avg       0.82      0.82      0.82      6517\n",
      "\n",
      "Test Accuracy: 0.8192272309107635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      3079\n",
      "           1       0.85      0.79      0.82      3443\n",
      "\n",
      "    accuracy                           0.82      6522\n",
      "   macro avg       0.82      0.82      0.82      6522\n",
      "weighted avg       0.82      0.82      0.82      6522\n",
      "\n",
      "Validation ROC AUC: 0.8947\n",
      "Test ROC AUC: 0.8963\n",
      "Validation PR AUC: 0.9198\n",
      "Test PR AUC: 0.9206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "\n",
    "def prepare_data(set_dir, week=None):\n",
    "    data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "    assessments = pd.read_csv(f\"{data_dir}/assessments.csv\")\n",
    "    student_info = pd.read_csv(f\"{set_dir}/student_info.csv\")\n",
    "    student_assessment = pd.read_csv(f\"{set_dir}/student_assessment.csv\")\n",
    "    student_reg = pd.read_csv(f\"{set_dir}/student_reg.csv\")\n",
    "    student_vle = pd.read_csv(f\"{set_dir}/student_vle.csv\")\n",
    "\n",
    "    if week is not None:\n",
    "        student_vle = student_vle[(student_vle['date'] // 7) <= week]\n",
    "        student_assessment = student_assessment[(student_assessment['date_submitted'] // 7) <= week]\n",
    "\n",
    "        student_reg['week_registered'] = student_reg['date_registration'] // 7\n",
    "        student_reg['days_since_registration'] = (week * 7) - student_reg['date_registration']\n",
    "        student_reg['days_since_registration'] = student_reg['days_since_registration'].clip(lower=0) # if any value in the days_since_registration column is less than 0, it is set to 0\n",
    "\n",
    "        student_assessment = pd.merge(\n",
    "            student_assessment, \n",
    "            assessments[['id_assessment', 'weight', 'assessment_type']], \n",
    "            on='id_assessment', \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "        student_assessment = student_assessment[student_assessment['weight'] > 0] \n",
    "        student_assessment = student_assessment[student_assessment['assessment_type'] != 'Exam']\n",
    "    \n",
    "        # Aggregate assessments per student\n",
    "        student_agg = student_assessment.groupby(\n",
    "            ['code_module', 'code_presentation', 'id_student']\n",
    "        ).agg(\n",
    "            mean_score=('score', 'mean'),\n",
    "            max_score=('score', 'max'),\n",
    "            min_score=('score', 'min'),\n",
    "            n_assessments=('score', 'count'),\n",
    "            weighted_score=('score', lambda x: (x * student_assessment.loc[x.index, 'weight']).sum() / 100)\n",
    "        ).reset_index()\n",
    "    \n",
    "        vle_agg = student_vle.groupby(['code_module', 'code_presentation', 'id_student']).agg(\n",
    "        total_clicks=('sum_click', 'sum'),\n",
    "        n_activities=('id_site', 'nunique'),\n",
    "        days_active=('date', 'nunique')\n",
    "        ).reset_index()\n",
    "\n",
    "        vle_agg['clicks_per_day'] = vle_agg['total_clicks'] / vle_agg['days_active']\n",
    "        \n",
    "        merge_keys = ['code_module', 'code_presentation', 'id_student']\n",
    "        df = student_info.merge(student_agg, on=merge_keys, how='left')\n",
    "        df = df.merge(vle_agg, on=merge_keys, how='left')\n",
    "        df = pd.merge(df, student_reg, on=merge_keys, how='left')\n",
    "    \n",
    "        nan_rows = df[df.isna().any(axis=1)]\n",
    "        print(f\"Found {len(nan_rows)} rows with NaN values\")\n",
    "        # print(nan_rows.head())\n",
    "    \n",
    "        assessment_cols = ['mean_score', 'max_score', 'min_score', 'weighted_score']\n",
    "        df[assessment_cols] = df[assessment_cols].fillna(-1)  # -1 indicates no assessments\n",
    "        df['n_assessments'] = df['n_assessments'].fillna(0)   # 0 assessments completed\n",
    "        \n",
    "        df['total_clicks'] = df['total_clicks'].fillna(0)\n",
    "        df['n_activities'] = df['n_activities'].fillna(0)\n",
    "        df['clicks_per_day'] = df['clicks_per_day'].fillna(0)\n",
    "        df['days_active'] = df['days_active'].fillna(0)\n",
    "    \n",
    "        df = df.drop(columns=['date_unregistration', 'mean_score', 'max_score', 'min_score'], errors='ignore')\n",
    "    \n",
    "        df = df.drop(columns=['n_assessments']) # because of multicollinearity\n",
    "        # Dropping equity related  features\n",
    "        df = df.drop(columns=['disability_Y', 'age_band', 'imd_band', 'highest_education', 'gender_M'])\n",
    "        # Dropping regions\n",
    "       # df = df.drop(columns=[reg for reg in df.columns if reg.startswith('region_')])\n",
    "        \n",
    "        y = df['final_result'].apply(lambda x: 1 if x in ['Fail', 'Withdrawn'] else 0)  # binary target\n",
    "    \n",
    "        X = df.drop(columns=['code_module', 'code_presentation', 'id_student', 'final_result'])\n",
    "        \n",
    "        return X, y\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # Gets predicted probabilities for the positive class (1)\n",
    "    y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # Getting the best threshold from our function\n",
    "    # threshold = plot_precision_recall_threshold_curve(y_val, y_val_probs, desired_recall=0.9)\n",
    "\n",
    "    # if threshold is not None:\n",
    "    #    # Converting the predicted probabilities on the validation set into binary predictions using the chosen threshold.\n",
    "    #    y_val_pred_thresh = (y_val_probs >= threshold).astype(int)\n",
    "    #    print(f\"\\n=== Evaluation at threshold {threshold:.3f} ===\")\n",
    "    #    print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred_thresh))\n",
    "    #    print(classification_report(y_val, y_val_pred_thresh))\n",
    "    \n",
    "    #    y_test_pred_thresh = (y_test_probs >= threshold).astype(int)\n",
    "    #    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred_thresh))\n",
    "    #    print(classification_report(y_test, y_test_pred_thresh))\n",
    "        \n",
    "    # Calculates AUC\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_probs)\n",
    "    test_pr_auc = average_precision_score(y_test, y_test_probs)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_probs)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "    \n",
    "    print(f\"Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\"Validation PR AUC: {val_pr_auc:.4f}\")\n",
    "    print(f\"Test PR AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "data_dir = Path.home() / \"Desktop\" / \"Logistic Regression Skewness Fixed\" / \"constant\"\n",
    "\n",
    "for week in range(1, 17):   \n",
    "    print(f\"Performance for the WEEK {week}\")\n",
    "    X_train, y_train = prepare_data(data_dir / \"train\", week)\n",
    "    X_val, y_val = prepare_data(data_dir / \"val\", week)\n",
    "    X_test, y_test = prepare_data(data_dir / \"test\", week)\n",
    "    \n",
    "    # Training\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,         # Number of trees\n",
    "        class_weight='balanced',  # Handles imbalance\n",
    "        max_depth=None,           # Lets trees grow fully\n",
    "        random_state=42,          # For reproducibility\n",
    "        n_jobs=-1                 # Uses all cores\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    evaluate_model(model, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c4e86-0d58-45ef-8f8b-b15449908f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_analytics)",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
